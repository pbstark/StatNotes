{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a6cea41-9c51-4c33-80df-72737d5226ac",
   "metadata": {},
   "source": [
    "# Conformal Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a3e4f1-081c-434a-8389-45d801ce238e",
   "metadata": {},
   "source": [
    "Core reference: Shafer and Vovk, 2008. A Tutorial on Conformal Prediction, _Journal of Machine Learning Research, 9_, 371-421.\n",
    "\n",
    "Basic problem set up: we observe items sequentially. Each item has a label, $y$, which could be numerical or categorical.\n",
    "There is some black-box model that makes a prediction $\\hat{y}$ of the value of $y$ for the next item, \n",
    "generally using side information $x$ (e.g., covariates).\n",
    "The predictor can \"learn\" from previous cases (also called _examples_): it does not have to stay the same over time.\n",
    "After each prediction $\\hat{y}$ is made, the true label $y$ is revealed.\n",
    "Thus,  $(x_1, y_1), \\ldots, (x_{n−1}, y_{n−1})$ and $x_n$ are available to predict $y_n$.\n",
    "\n",
    "The problem statement is, given an acceptable error probability $\\epsilon$, construct a \"prediction region\" $\\Gamma^\\epsilon$ of labels that contains the label of the next item with probability at least $1-\\epsilon$.\n",
    "A $1-\\epsilon$ prediction region is _valid_ if it contains the truth at least $1-\\epsilon$ of the time.\n",
    "\n",
    "Conformal prediction works for any prediction method: regression, Bayesian modeling, support-vector machines, neural networks, etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a3e699-1582-48f4-91e2-ca372bfc95ef",
   "metadata": {},
   "source": [
    "Recall [the definition of a _multiset_ or _bag_](./math-foundations.ipynb#Multisets): like a set, a bag is a collection of things, but unlike a set, it can contain multiple copies of the same thing. It amounts to an unordered list.\n",
    "We will use $\\Lbag \\cdot \\Rbag$ to denote a bag."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9fc7066-b694-49da-8e58-4662f59dcc02",
   "metadata": {},
   "source": [
    "The basic assumption of conformal prediction is that the cases are _exchangeable_, which is true if they are IID, but not quite as restrictive as IID. \n",
    "(There has been work on weakening that assumption: see, e.g., Foygel, R.B., E.J. Candes, A. Ramdas, and R.J. Tibshirani, 2022.  Conformal prediction beyond exchangeability, https://arxiv.org/abs/2202.13415.)\n",
    "\n",
    "One definition of exchangability of a finite set of random variables $\\{Z_1, \\ldots, Z_n\\}$ is that their joint probability distribution is invariant under permutations of the labels. That is, the distribution of $(Z_1, \\ldots, Z_n)$ is the same as the distribution $(Z_{\\pi_1}, \\ldots, Z_{\\pi_n})$ for every permutation $\\pi$ of $\\{1, \\ldots, n\\}$.\n",
    "An infinite series of random variables $Z_1, Z_2, \\ldots$ is exchangable if the finite collection $\\{Z_1, \\ldots, Z_n\\}$\n",
    "is exchangeable for every $n$.\n",
    "\n",
    "Shafer & Vovk also define exchangeability using a betting protocol, as follows.\n",
    "\n",
    "### Backward-Looking Betting Protocol (Shaver & Vovk, 2008)\n",
    "\n",
    "Two players, Alice & Bob.\n",
    "+ $\\mathcal{K}_N := 1.\n",
    "+ Alice announces a bag $\\mathcal{B}_N$ of size $N$.\n",
    "+ for $n = N, N−1, \\ldots, , 2, 1$:\n",
    "    + Bob bets on $z_n$ at odds set by $\\mathbb{P} \\{z_n = a || \\mathcal{B}_n = \\Lbag a_1, \\ldots, a_n \\Rbag \\} = k/n$, where $k$ is the number of times $a$ occurs in $\\mathcal{B}_n$.\n",
    "    + Alice announces $z_n \\in \\mathcal{B}_n$\n",
    "    + $\\mathcal{K}_{n−1} :=  \\mathcal{K}_n$ plus Bob's winnings on $z_n$\n",
    "    + $\\mathcal{B}_{n−1} := \\mathcal{B}_n \\setminus \\Lbag z_n \\Rbag$\n",
    "Bob's moves are constrained to guarantee that his capital $\\mathcal{K}_n$ will be nonnegative for all $n$, no matter how Alice\n",
    "moves.\n",
    "\n",
    "Shafer & Vovk define exchangeability as saying that Bob will not multiply his initial capital $\\mathcal{K}_N$ by a\n",
    "large factor in this game."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760a552e-4964-468d-a814-8d1a593ba1ee",
   "metadata": {},
   "source": [
    "Shafer & Vovk consider two cases, one of which is a special case of the other:\n",
    "\n",
    "1. Predict using old examples alone. Just before observing $z_n$,  predict it \n",
    "using the previous examples $(z_1, \\ldots , z_{n−1})$.\n",
    "\n",
    "2. Predict using features (covariates) of the new example. Each example $z_i = (x_i, y_i)$, where $x_i$ is side information\n",
    "and $y_i$ is a label. The data are $x_1, y_1, \\ldots , x_N, y_N$. Just before observing $y_n$, we predict it from $x_n$ and $(z_i)_{i=1}^{n-1}$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee08515-8dd8-49ea-8945-b8f01fad7185",
   "metadata": {},
   "source": [
    "An essential ingredient in conformal prediction is a measure of _nonconformity_ between an _example_ $z$ and a bag $\\mathcal{B}$ of other examples, a real-valued function $A(\\mathcal{B}, z)$.\n",
    "If there is a distance function defined on examples, $d(z, z')$, the nonconformity measure could be \n",
    "defined using the distance between a point estimator $\\hat{z}$ and the example:\n",
    "\\begin{equation}\n",
    "A(\\mathcal{B}, z) := d(\\hat{z}(\\mathcal{B}), z).\n",
    "\\end{equation}\n",
    "In general, the precision of the prediction regions will depend on the nonconformity measure, but the validity of the prediction regions will not.\n",
    "The prediction regions that conformal prediction produces are invariant under monotone increasing\n",
    "transformations of $A$.\n",
    "Hence, in this approach to constructing a nonconformity measure, the particular choice of distance measures $d(\\cdot, \\cdot)$ \n",
    "is less important than the choice of point predictors $\\hat{z}$.\n",
    "\n",
    "If the labels are real numbers, one could define $A(\\mathcal{B}, z)$ in a number of simple ways, such as\n",
    "\\begin{equation}\n",
    " A(\\mathcal{B}, z) := |\\bar{z}_{\\mathcal{B}} - z|,\n",
    "\\end{equation}\n",
    "where $\\bar{z}_{\\mathcal{B}} := (\\sum_{a \\in {\\mathcal{B}}} a)/|{\\mathcal{B}}|."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ddbb71-c507-4282-936f-6f805ce9d572",
   "metadata": {},
   "source": [
    "## Conformal prediction algorithm without covariates (Shafer & Vovk)\n",
    "\n",
    "Input: Nonconformity measure $A$, significance level $\\epsilon$, examples $z_1, \\ldots, z_{n-1}$,\n",
    "example $z$.\n",
    "\n",
    "Task: Decide whether to include $z$ in $\\Gamma^\\epsilon(z_1, \\ldots, z_{n−1})$.\n",
    "\n",
    "Algorithm:\n",
    "1. Provisionally set $z_n := z$.\n",
    "2. For $i = 1, \\ldots,n$, set $\\alpha_i := A( \\Lbag z_1, \\ldots ,z_n \\Rbag \\setminus \\Lbag z_i \\Rbag, ,z_i)$.\n",
    "3. Set $p_z := \\frac{1}{n}\\left | \\left \\{i \\in \\{1, \\ldots, n\\}: \\alpha_i \\ge \\alpha_n \\right \\} \\right |$.\n",
    "4. Include $z$ in $\\Gamma^\\epsilon(z_1, \\ldots ,z_{n−1})$ iff $p_z > \\epsilon$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac89504-b59e-4af0-af30-346c96591505",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
